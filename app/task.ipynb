{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from features import BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File ‘comments.tsv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('../../datasets/comments_small_dataset/comments.tsv', sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    os.system('wget https://raw.githubusercontent.com/girafe-ai/ml-course/master/datasets/comments_small_dataset'\n",
    "              '/comments.tsv -nc')\n",
    "    data = pd.read_csv(\"comments.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: How to be a grown-up at work: replace \"I don't want to do that\" with \"Ok, great!\".\n",
      "after: how to be a grown-up at work : replace \" i don't want to do that \" with \" ok , great ! \" .\n"
     ]
    }
   ],
   "source": [
    "texts = data['comment_text'].values\n",
    "target = data['should_ban'].values\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(texts, target, test_size=0.5, random_state=42)\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "texts_train = [preprocess(text) for text in texts_train]  # <YOUR CODE>\n",
    "texts_test = [preprocess(text) for text in texts_test]  # <YOUR CODE>\n",
    "\n",
    "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
    "print(\"before:\", text, )\n",
    "print(\"after:\", preprocess(text), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT CREATED SUCCESSFULLY\n"
     ]
    }
   ],
   "source": [
    "MLFLOW_SERVER_URI = 'http://web:5000'\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER_URI)\n",
    "\n",
    "EXP_NAME = \"lsml\"\n",
    "EXP_ID = mlflow.create_experiment(EXP_NAME)\n",
    "\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "with mlflow.start_run() as run:\n",
    "    assert run.info.experiment_id == EXP_ID\n",
    "    print(\"Experiment created successfully\".upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example features: ['!', 'around', 'close', 'editors', 'h', 'last', 'notable', 'recent', 'stated', 'unsigned']\n",
      "train AUC: 0.9995511309895959\n",
      "test  AUC: 0.8273387083796006\n",
      "example features: ['!', 'accessed', 'are', 'blocks', 'close', 'dead', 'education', 'final', 'greek', 'ignored', 'know', 'market', 'none', 'physical', 'quote', 'rumors', 'solution', 'teach', 'ultimately', 'western']\n",
      "train AUC: 0.9999198448195707\n",
      "test  AUC: 0.8321344083425868\n",
      "example features: ['!', '55', 'afd', 'appears', 'basically', 'bullied', 'cite', 'contrast', 'declared', 'draw', 'everyone', 'fired', 'glad', 'herself', 'india', 'justine', 'living', 'messages', 'neutral', 'origins', 'plenty', 'pull', 'repeatedly', 'schulz', 'slap', 'style', 'that', 'truthseekers', 'violating', 'willing']\n",
      "train AUC: 0.9999839689639141\n",
      "test  AUC: 0.8321344083425868\n",
      "example features: ['!', '18', '::', 'affiliation', 'anything', 'authority', 'bigger', 'busking', 'chiliboy', 'compounds', 'crap', 'deleting', 'dog', 'eminem', 'extensive', 'florida', 'geogre', 'hardly', 'however', 'insignificant', 'just', 'lexeme', 'makers', 'mistaken', 'never', 'older', 'peoples', 'post', 'publications', 'referencing', 'rfa', 'seem', 'sincerily', 'spilling', 'super', 'that', 'transform', 'up', 'washington', 'word']\n",
      "train AUC: 0.9999839689639141\n",
      "test  AUC: 0.8342023527897134\n"
     ]
    }
   ],
   "source": [
    "# k_min = sys.argv[1] if len(sys.argv) > 1 else 1000\n",
    "k_min = 5000\n",
    "\n",
    "for k in [min(1000, k_min), min(2000, k_min), min(3000, k_min), min(4000, k_min)]:\n",
    "    with mlflow.start_run():\n",
    "        bow = BoW(k)\n",
    "        bow.fit(texts_train)\n",
    "        print('example features:', sorted(bow.get_vocabulary())[::100])\n",
    "\n",
    "        X_train_bow = bow.transform(texts_train)\n",
    "        X_test_bow = bow.transform(texts_test)\n",
    "\n",
    "        bow_model = LogisticRegression().fit(X_train_bow, y_train)\n",
    "\n",
    "        for name, X, y, model in [\n",
    "            ('train', X_train_bow, y_train, bow_model),\n",
    "            ('test ', X_test_bow, y_test, bow_model)\n",
    "        ]:\n",
    "            proba = model.predict_proba(X)[:, 1]\n",
    "            auc = roc_auc_score(y, proba)\n",
    "\n",
    "            print(f\"{name} AUC: {auc}\")\n",
    "\n",
    "            # mlflow stuff\n",
    "            mlflow.log_param(\"k\", k)\n",
    "            mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "            mlflow.sklearn.log_model(bow_model, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URI)\n",
    "experiment = client.get_experiment_by_name(EXP_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
