{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from features import BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File ‘comments.tsv’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('../../datasets/comments_small_dataset/comments.tsv', sep='\\t')\n",
    "except FileNotFoundError:\n",
    "    os.system('wget https://raw.githubusercontent.com/girafe-ai/ml-course/master/datasets/comments_small_dataset'\n",
    "              '/comments.tsv -nc')\n",
    "    data = pd.read_csv(\"comments.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before: How to be a grown-up at work: replace \"I don't want to do that\" with \"Ok, great!\".\n",
      "after: how to be a grown-up at work : replace \" i don't want to do that \" with \" ok , great ! \" .\n"
     ]
    }
   ],
   "source": [
    "texts = data['comment_text'].values\n",
    "target = data['should_ban'].values\n",
    "texts_train, texts_test, y_train, y_test = train_test_split(texts, target, test_size=0.5, random_state=42)\n",
    "\n",
    "tokenizer = TweetTokenizer()\n",
    "preprocess = lambda text: ' '.join(tokenizer.tokenize(text.lower()))\n",
    "texts_train = [preprocess(text) for text in texts_train]  # <YOUR CODE>\n",
    "texts_test = [preprocess(text) for text in texts_test]  # <YOUR CODE>\n",
    "\n",
    "text = 'How to be a grown-up at work: replace \"I don\\'t want to do that\" with \"Ok, great!\".'\n",
    "print(\"before:\", text, )\n",
    "print(\"after:\", preprocess(text), )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def generate_submission():  # Report generation\n",
    "    client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URI)\n",
    "\n",
    "    runs = {}\n",
    "    models = [\n",
    "        {'name': m.name,\n",
    "         'versions': [\n",
    "             {'current_stage': v.current_stage, 'run_id': v.run_id, 'status': v.status}\n",
    "             for v in m.latest_versions if m.name == 'sk-learn-model-ci']}\n",
    "        for m in client.search_registered_models()\n",
    "    ]\n",
    "    for e in client.list_experiments():\n",
    "        if e.name == 'Twitter-Test2':\n",
    "            for run_info in client.search_runs(e.experiment_id):\n",
    "                run = mlflow.get_run(run_info.info.run_id)\n",
    "                runs[run_info.info.run_id] = {'run_id': run_info.info.run_id, 'tags': run.data.tags,\n",
    "                                         'params': run.data.params,\n",
    "                                         'metrics': run.data.metrics}\n",
    "    versions = [{'version': v.version, 'run_id': v.run_id} for v in\n",
    "                client.search_model_versions(f\"name='{nlp_model_name}'\")]\n",
    "    with open('submission.json', 'w') as f:\n",
    "        json.dump({'runs': runs, 'models': models, 'versions': versions}, f)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MLFLOW_SERVER_URI = 'http://web:5000'\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URI)\n",
    "mlflow.set_tracking_uri(MLFLOW_SERVER_URI)\n",
    "\n",
    "EXP_NAME = \"Twitter-Test2\"\n",
    "EXP_ID = mlflow.create_experiment(EXP_NAME)\n",
    "\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    assert run.info.experiment_id == EXP_ID\n",
    "    print(\"Experiment created successfully\".upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "for k in range(1000, 10000, 500):\n",
    "    with mlflow.start_run():\n",
    "        bow = BoW(k)\n",
    "        bow.fit(texts_train)\n",
    "        print('example features:', sorted(bow.get_vocabulary())[::100])\n",
    "\n",
    "        X_train_bow = bow.transform(texts_train)\n",
    "        X_test_bow = bow.transform(texts_test)\n",
    "\n",
    "        bow_model = LogisticRegression().fit(X_train_bow, y_train)\n",
    "\n",
    "        for name, X, y, model in [\n",
    "            ('train', X_train_bow, y_train, bow_model),\n",
    "            ('test ', X_test_bow, y_test, bow_model)\n",
    "        ]:\n",
    "            proba = model.predict_proba(X)[:, 1]\n",
    "            auc = roc_auc_score(y, proba)\n",
    "\n",
    "            print(f\"{name} AUC: {auc}\")\n",
    "\n",
    "            # mlflow stuff\n",
    "            mlflow.log_param(\"k\", k)\n",
    "            mlflow.log_metric(\"AUC\", auc)\n",
    "\n",
    "            mlflow.sklearn.log_model(bow_model, \"model\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "experiment = client.get_experiment_by_name(EXP_NAME)\n",
    "nlp_model_name = \"Twitter11\"\n",
    "client.create_registered_model(nlp_model_name)\n",
    "\n",
    "# staging model\n",
    "run_info = client.search_runs(experiment.experiment_id)[0]\n",
    "result = client.create_model_version(\n",
    "    name=nlp_model_name,\n",
    "    source=f\"{run_info.artifact_uri}/model\",\n",
    "    run_id=run_info.run_id\n",
    ")\n",
    "client.transition_model_version_stage(\n",
    "    name=nlp_model_name,\n",
    "    version=result.version,\n",
    "    stage=\"Staging\"\n",
    ")\n",
    "# prod model\n",
    "run_info = client.search_runs(experiment.experiment_id)[-1]\n",
    "result = client.create_model_version(\n",
    "    name=nlp_model_name,\n",
    "    source=f\"{run_info.artifact_uri}/model\",\n",
    "    run_id=run_info.run_id\n",
    ")\n",
    "client.transition_model_version_stage(\n",
    "    name=nlp_model_name,\n",
    "    version=result.version,\n",
    "    stage=\"Production\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient(MLFLOW_SERVER_URI)\n",
    "experiment = client.get_experiment_by_name(EXP_NAME)\n",
    "client.search_runs(experiment.experiment_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "current_staging = \\\n",
    "[v for v in client.search_model_versions(f\"name='{nlp_model_name}'\") if v.current_stage == 'Staging'][\n",
    "    -1]\n",
    "\n",
    "client.set_tag(current_staging.run_id, \"staging\", \"failed\")\n",
    "\n",
    "current_prod = \\\n",
    "[v for v in client.search_model_versions(f\"name='{nlp_model_name}'\") if v.current_stage == 'Production'][\n",
    "    -1]\n",
    "prod_metrics = client.get_run(current_prod.run_id).data.metrics\n",
    "current_staging = \\\n",
    "[v for v in client.search_model_versions(f\"name='{nlp_model_name}'\") if v.current_stage == 'Staging'][\n",
    "    -1]\n",
    "current_staging_metrics = client.get_run(current_staging.run_id).data.metrics\n",
    "\n",
    "# Task 1\n",
    "for run_info in client.search_runs(experiment.experiment_id):\n",
    "    run = mlflow.get_run(run_info.info.run_id)\n",
    "\n",
    "    # Compare each experiment with prod\n",
    "    current_metrics = client.get_run(run_info.info.run_id).data.metrics\n",
    "    current_tags = client.get_run(run_info.info.run_id).data.tags\n",
    "\n",
    "    client.set_tag(run_info.info.run_id, \"compared_with\", current_prod.version)\n",
    "\n",
    "    if all(current_metrics[k] > v for k, v in prod_metrics.items()):\n",
    "        client.set_tag(run_info.info.run_id, \"staging\", \"rc\")\n",
    "    else:\n",
    "        client.set_tag(run_info.info.run_id, \"staging\", \"rejected\")\n",
    "\n",
    "\n",
    "# find production id and metrics\n",
    "def get_production(client_):\n",
    "    for mv in client_.search_model_versions(f\"name='{nlp_model_name}'\"):\n",
    "        if dict(mv)['current_stage'] == 'Production':\n",
    "            return mv\n",
    "\n",
    "\n",
    "prod_mv = get_production(client)\n",
    "print(f'Production ID: {prod_mv.run_id}')\n",
    "print(f'Production Version: {prod_mv.version}')\n",
    "\n",
    "\n",
    "# find production id and metrics\n",
    "def get_staging(client_):\n",
    "    for mv in client_.search_model_versions(f\"name='{nlp_model_name}'\"):\n",
    "        if dict(mv)['current_stage'] == 'Staging':\n",
    "            return mv\n",
    "\n",
    "\n",
    "staging_mv = get_staging(client)\n",
    "print(f'Staging ID: {staging_mv.run_id}')\n",
    "print(f'Staging Version: {staging_mv.version}')\n",
    "\n",
    "# Task 2\n",
    "metrics = {}\n",
    "\n",
    "for run_info in client.search_runs(experiment.experiment_id):\n",
    "    run = mlflow.get_run(run_info.info.run_id)\n",
    "\n",
    "    # for all models that pass the initial selection (if experiment is a release candidate)\n",
    "    if 'rc' in run.data.tags['staging']:\n",
    "        test_metrics = client.get_run(run_info.info.run_id).data.metrics\n",
    "\n",
    "        if all(test_metrics[k] > v for k, v in prod_metrics.items()):\n",
    "            client.set_tag(run_info.info.run_id, \"staging\", \"rc\")\n",
    "            prod = client.create_model_version(\n",
    "                name=nlp_model_name,\n",
    "                source=f\"{run_info.info.artifact_uri}/model\",\n",
    "                run_id=run_info.info.run_id\n",
    "            )\n",
    "            client.transition_model_version_stage(\n",
    "                name=nlp_model_name,\n",
    "                version=prod.version,\n",
    "                stage=\"Production\"\n",
    "            )\n",
    "            prod_metrics = client.get_run(prod.run_id).data.metrics\n",
    "        metrics[run_info.info.run_id] = test_metrics.get('AUC')\n",
    "\n",
    "print(f'Production ID: {get_production(client).run_id}')\n",
    "print(f'Production Version: {get_production(client).version}', end=\"\\n\\n\")\n",
    "\n",
    "print(f'Staging ID: {get_staging(client).run_id}')\n",
    "print(f'Staging Version: {get_staging(client).version}')\n",
    "\n",
    "print(f'Production Metrics: {prod_metrics}')\n",
    "print(f'Production Metrics: {mlflow.get_run(get_production(client).run_id).data.metrics}')\n",
    "\n",
    "for run_info in client.search_runs(experiment.experiment_id):\n",
    "    for tag in ['staging', 'compared_with']:\n",
    "        client.delete_tag(run_info.info.run_id, tag)\n",
    "\n",
    "generate_submission()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
